---
title: MapReduce分布式计算编程
date: 2021-12-02
tags:
  - Java
  - Hadoop
categories:
  - Hadoop笔记
---

## MapReduce 分布式计算编程

- MapReduce 的思路

1. split 过程：
   - 将原始数据分解成若干 block（每个 block 包含 n 行数据）
2. map 过程：由用户定义方法
   - 将 block 包含的数据，依次调用 map 方法（一行调用一次）,每次调用 map 传递数据（key：行号，value：行的内容）
   - map 方法对每行的内容进行解析处理，根据具体内容，以新的 key 和 value 输出。
3. shuffle 过程：
   - 分组和排序，将所有 map 的输出按照相同的 key 的数据放在一组，并按照 key 排序。
4. reduce 过程：由用户定义方法
   - 将相同的 key 的数据传递给 reduce 方法，reduce 方法对数据进行汇总，输出
5. 合并所有 reduce 的输出到一个文件中，默认 为`part-r-00000`。

## 案例：手机流量统计

> 手机号码流量日志文件，格式：手机号码，时间，网址，流量大小
>
> 目标：给定 n 个日志文件，统计每个号码的流量，分时间段的流量统计

1.  创建 map/reduce 项目
2.  新建主类 FlowCount
3.  创建 map 类 FlowCountMapper
4.  创建 reduce 类 FlowCountReducer

导出 jar 包运行

- 创建目录 `hdfs dfs -mkdir /flowcount`

- 创建两个流量日志文件，`1207.txt` `1208.txt`

  ```shell
  vi 1207.txt
  9909,20201-12-07,qq.com,1220
  9908,20201-12-07,qq.com,1200

  vi 1208.txt
  9909,20201-12-08,qq.com,1000
  9908,20201-12-08,qq.com,800

  ```

- 将两个文件上传到 hdfs 上 `hdfs dfs -put 1207.txt /flowcount` `hdfs dfs -put 1208.txt /flowcount`

- 执行 jar 文件，`hadoop jar flowcount.jar`

- 如果输出目录已存在会报错，删除输出目录 `hdfs dfs -rm -r /flowcount/out`

- 查看执行结果，列出目录下的文件，`hdfs dfs -ls /flowcount/out`

- 查看结果文件，`hdfs dfs -cat /flowcount/out/part-r-00000`

- 下载运行结果到 txt 文件中`hdfs dfs -get /flowcount/out/part-r-00000 a.txt`

:::tip
流量统计案例源码如下
:::

## FlowCount.java

```java
package phoneFlowCount;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;


// Map/Reduce手机流量统计
public class FlowCount {

	public static void main(String[] args) throws Exception {
		// TODO Auto-generated method stub
		// 1. 创建一个任务（Job）对象
		Job job = new Job();
		job.setJobName("flowcount");
		job.setJarByClass(FlowCount.class);

		// 2.设置要读取的日志数据文件所在目录路径
		FileInputFormat.addInputPaths(job, "/flowcount");

		// 3.设置输出结果文件路径，输出的文件夹如果存在会报错
		FileOutputFormat.setOutputPath(job, new Path("/flowcount/out"));

		// 4.设置要调用的map方法在所在类
		job.setMapperClass(FlowCountMapper.class);
		// 5.设置要调用的map方法在所在类
		job.setReducerClass(FlowCountReducer.class);

		// 设置map输出的key,value类型
		job.setOutputKeyClass(Text.class); // 手机尾号
		job.setOutputValueClass(IntWritable.class); // 总流量值

		// 6.将任务部署到Hadoop上进行分布式计算，等待结果，true表示同步
		job.waitForCompletion(true);
	}

}
```

## FlowCountMapper.java

```java
package phoneFlowCount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

// 指明 输入输出 的 key 和 value 类型
public class FlowCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {

	// 重写map方法
	@Override
	protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
		// TODO Auto-generated method stub

		// 调用map时，key 行号，value 行内容
		// 1.解析value，分离手机号和流量
		String s = value.toString();
		String[] ss = s.split(",");
		String phone = ss[0];  // 手机号
		int flow = Integer.parseInt(ss[3]); // 流量

		// 2. 以手机号phone作为key，流量flow作为value，输出
		context.write(new Text(phone), new IntWritable(flow));
	}
}
```

## FlowCountReducer.java

```java
package phoneFlowCount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

//指明 输入输出 的 key 和 value 类型
public class FlowCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {

	// 重写reduce方法
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
		// TODO Auto-generated method stub

		// 传递的数据是map输出结果里面相同的key，值为流量数组
		// 18757018850 [100,120,80....]
		// 对同一key中各个流量数值进行汇总
		int sum = 0;
		for (IntWritable x : values) {
			sum += x.get();
		}
		// 以手机号码为key，总流量为value进行输出
		context.write(key, new IntWritable(sum));
	}
}
```
